# Vertiport Autonomy v1.0.0 - Initial Release

ğŸš€ **First stable release of the Vertiport Autonomy platform!**

Vertiport Autonomy is a Deep Reinforcement Learning platform for autonomous vertiport coordination, featuring a comprehensive simulation environment, training framework, and evaluation system.

## ğŸ¯ What's New

### Core Features
- **Vertiport simulation engine** with discrete-time dynamics
- **Gymnasium-compatible DRL environment** for standardized RL training
- **Comprehensive event logging system** for detailed analysis
- **Scenario-driven configuration** with YAML support and Pydantic validation

### Agent Framework
- **Abstract base agent class** for extensibility
- **Simple heuristic baseline agent** for benchmarking
- **DRL agent infrastructure** (PPO-based with stable-baselines3)
- **Multi-agent support capabilities**

### Training System
- **Standard PPO training pipeline** with customizable hyperparameters
- **Curriculum learning implementation** with progressive difficulty
- **Three-phase training progression**: Easy â†’ Intermediate â†’ Hard scenarios
- **Automatic model checkpointing and evaluation**

### Evaluation Framework
- **Comprehensive KPI tracking**: safety, efficiency, resource usage
- **Statistical analysis** with confidence intervals
- **Multi-scenario evaluation** support
- **CSV and JSON result exports**

### Professional Development Tools
- **Modern Python packaging** with `pyproject.toml`
- **Comprehensive test suite** with pytest
- **Code quality tools**: Black, isort, flake8, mypy, bandit
- **Pre-commit hooks** for automated quality checks
- **GitHub Actions CI/CD pipeline**
- **Sphinx documentation** with API reference

## ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/N-cryptd/vertiport-autonomy.git
cd vertiport-autonomy

# Install in development mode
pip install -e .
```

## ğŸš€ Quick Start

```bash
# Run evaluation with heuristic agent
python scripts/evaluate.py --agent heuristic --scenario scenarios/easy_world.yaml --episodes 10

# Train a new PPO agent
python scripts/train.py --scenario scenarios/easy_world.yaml --timesteps 50000

# Train with curriculum learning
python scripts/train_curriculum.py --timesteps 100000
```

## ğŸ“Š Test Coverage

- **47% code coverage** with comprehensive test suite
- **All core functionality tested** including simulation, training, and evaluation
- **Integration tests** for end-to-end workflows

## ğŸ›¡ï¸ Code Quality

- âœ… **Security scan passed** (bandit)
- âœ… **Code formatting** standardized (Black)
- âœ… **Import sorting** organized (isort)
- âœ… **Linting checks** completed (flake8)
- âœ… **Type hints** where applicable (mypy)

## ğŸ“ Project Structure

```
vertiport-autonomy/
â”œâ”€â”€ ğŸ“ src/vertiport_autonomy/     # Main package
â”‚   â”œâ”€â”€ ğŸ“ agents/                 # Agent implementations
â”‚   â”œâ”€â”€ ğŸ“ config/                 # Configuration handling
â”‚   â”œâ”€â”€ ğŸ“ core/                   # Core simulation engine
â”‚   â”œâ”€â”€ ğŸ“ evaluation/             # Evaluation framework
â”‚   â””â”€â”€ ğŸ“ training/               # Training pipelines
â”œâ”€â”€ ğŸ“ scripts/                    # Entry point scripts
â”œâ”€â”€ ğŸ“ scenarios/                  # YAML configurations
â”œâ”€â”€ ğŸ“ tests/                      # Test suite
â”œâ”€â”€ ğŸ“ docs/                       # Documentation
â””â”€â”€ ğŸ“ .github/                    # CI/CD workflows
```

## ğŸ”§ Configuration

The platform uses YAML-based scenario configuration with Pydantic validation:

```yaml
vertiport:
  num_fatos: 4
  num_gates: 8
  runway_length: 100.0

traffic:
  arrival_rate: 0.1
  departure_rate: 0.08
  peak_hours: [8, 9, 17, 18]

simulation:
  max_timesteps: 1000
  time_step_duration: 1.0
```

## ğŸ“š Documentation

- **API Reference**: Complete Sphinx documentation
- **Getting Started Guide**: Quick setup and usage
- **Configuration Guide**: Scenario customization
- **Training Tutorials**: Step-by-step training guides

## ğŸ¤ Contributing

We welcome contributions! Please see [`CONTRIBUTING.md`](CONTRIBUTING.md) for guidelines.

## ğŸ“„ License

This project is licensed under the MIT License - see the [`LICENSE`](LICENSE) file for details.

## ğŸ™ Acknowledgments

Built with:
- [Gymnasium](https://gymnasium.farama.org/) - RL environment standard
- [stable-baselines3](https://stable-baselines3.readthedocs.io/) - RL algorithms
- [Pydantic](https://pydantic.dev/) - Data validation
- [PyYAML](https://pyyaml.org/) - Configuration parsing

---

**Full Changelog**: Initial release - no previous versions to compare.